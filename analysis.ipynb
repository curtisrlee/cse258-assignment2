{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_folder(results_folder):\n",
    "    filepath_list = []\n",
    "    for filepath in os.listdir(results_folder):\n",
    "        # print(filepath)\n",
    "        if filepath.split('.')[-1] == 'pkl':\n",
    "            filepath_list.append(filepath)\n",
    "    filepath_list.sort()\n",
    "\n",
    "    results = []\n",
    "    for filepath in filepath_list:\n",
    "        with open(os.path.join(results_folder, filepath), \"rb\") as pkl_file:\n",
    "            data = pickle.load(pkl_file)\n",
    "            results.append(data)\n",
    "\n",
    "    # print(filepath_list)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results1', 'results2', 'results3', 'results4', 'results5', 'results6']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dirs = [ d for d in os.listdir('.') if 'results' in d ]\n",
    "results_dirs.sort()\n",
    "results_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = [ (results_dir, scrape_folder(results_dir)) for results_dir in results_dirs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results6\n",
      "                           name  test_loss  epochs\n",
      "1                       Books_5  20.647181      10\n",
      "2  Clothing_Shoes_and_Jewelry_5  20.824848      10\n",
      "5            Home_and_Kitchen_5  21.216169      10\n",
      "3                 Electronics_5  21.671600      10\n",
      "7               Movies_and_TV_5  19.953064      10\n",
      "6                Kindle_Store_5  20.130110      10\n",
      "0                  Automotive_5  23.079222      10\n",
      "4    Grocery_and_Gourmet_Food_5  22.319535      10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295956/2516613375.py:24: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:24: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:24: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:24: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:24: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:24: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n",
      "/tmp/ipykernel_295956/2516613375.py:28: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n"
     ]
    }
   ],
   "source": [
    "droppables = ['input',]\n",
    "\n",
    "for results_dir, results in results_all:\n",
    "    results_flat = []\n",
    "    for result in results:\n",
    "        # print(result['results'][-1])\n",
    "        entry = {}\n",
    "        entry.update({'name': os.path.split(result['batches_folder'])[1] })\n",
    "        entry.update({'train_loss': result['results'][-1]['obj']})\n",
    "        entry.update({'test_loss': result['results'][-1]['test:']})\n",
    "        entry.update(result['args'])\n",
    "        entry.update({'dataset_len': result['dataset_len']})\n",
    "        # entry.update({'baseline': result['baseline']})\n",
    "        results_flat.append(entry)\n",
    "\n",
    "    df = pd.DataFrame(results_flat)\n",
    "    df.drop(droppables, axis=1, inplace=True)\n",
    "    df.insert(0, 'test_loss', df.pop('test_loss'))\n",
    "    df.insert(0, 'name', df.pop('name'))\n",
    "    df.sort_values(by='dataset_len', ascending=False, inplace=True)\n",
    "\n",
    "    df.to_csv(os.path.join(results_dir, results_dir+'.csv'))\n",
    "    with open(os.path.join(results_dir, results_dir+'.tex'), 'w') as tex_file:\n",
    "        df.to_latex(tex_file)\n",
    "\n",
    "    df_simp = df.drop('train_loss learning_rate split factors regularization dataset_len'.split(), axis=1, inplace=True)\n",
    "    with open(os.path.join(results_dir, results_dir+'_simp.tex'), 'w') as tex_file:\n",
    "        df.to_latex(tex_file)\n",
    "\n",
    "print(results_dir)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295956/2098141317.py:16: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(tex_file)\n"
     ]
    }
   ],
   "source": [
    "results_flat = []\n",
    "for result in results_all[-1][1]:\n",
    "    # print(result['results'][-1])\n",
    "    entry = {}\n",
    "    entry.update({'name': os.path.split(result['batches_folder'])[1] })\n",
    "    entry.update({'baseline': result['baseline']})\n",
    "    entry.update({'dataset_len': result['dataset_len']})\n",
    "    results_flat.append(entry)\n",
    "\n",
    "df = pd.DataFrame(results_flat)\n",
    "df.insert(0, 'name', df.pop('name'))\n",
    "df.sort_values(by='dataset_len', ascending=False, inplace=True)\n",
    "\n",
    "df.to_csv('baseline.csv')\n",
    "with open('baseline.tex', 'w') as tex_file:\n",
    "    df.to_latex(tex_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('results6',\n",
       " [{'data_path': 'data/Automotive_5.json.gz',\n",
       "   'batches_folder': 'data/Automotive_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Automotive_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 11.929574, 'test:': 23.193982950216913},\n",
       "    {'obj': 11.079374, 'test:': 23.1819080462496},\n",
       "    {'obj': 10.8355465, 'test:': 23.169436931439982},\n",
       "    {'obj': 10.926883, 'test:': 23.156771727936228},\n",
       "    {'obj': 10.991223, 'test:': 23.14400038747803},\n",
       "    {'obj': 10.906979, 'test:': 23.131143176142526},\n",
       "    {'obj': 10.703563, 'test:': 23.11823608010682},\n",
       "    {'obj': 10.713844, 'test:': 23.105279154618486},\n",
       "    {'obj': 10.68549, 'test:': 23.092271318988182},\n",
       "    {'obj': 10.738464, 'test:': 23.0792224515446}],\n",
       "   'mse': 23.0792224515446,\n",
       "   'baseline': 23.205572092425076,\n",
       "   'dataset_len': 208},\n",
       "  {'data_path': 'data/Books_5.json.gz',\n",
       "   'batches_folder': 'data/Books_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Books_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 23.502392, 'test:': 20.741624694149735},\n",
       "    {'obj': 15.352013, 'test:': 20.731413093730808},\n",
       "    {'obj': 13.013258, 'test:': 20.72111329222466},\n",
       "    {'obj': 14.189876, 'test:': 20.7107371071531},\n",
       "    {'obj': 15.092127, 'test:': 20.700274579246955},\n",
       "    {'obj': 13.988037, 'test:': 20.689744181633614},\n",
       "    {'obj': 12.53151, 'test:': 20.67915781713494},\n",
       "    {'obj': 11.924321, 'test:': 20.668523681736346},\n",
       "    {'obj': 12.0862, 'test:': 20.65786165341707},\n",
       "    {'obj': 12.15423, 'test:': 20.64718061440872}],\n",
       "   'mse': 20.64718061440872,\n",
       "   'baseline': 20.751694705389948,\n",
       "   'dataset_len': 3316},\n",
       "  {'data_path': 'data/Clothing_Shoes_and_Jewelry_5.json.gz',\n",
       "   'batches_folder': 'data/Clothing_Shoes_and_Jewelry_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Clothing_Shoes_and_Jewelry_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 18.107815, 'test:': 20.912619432630112},\n",
       "    {'obj': 13.071861, 'test:': 20.903187353292196},\n",
       "    {'obj': 11.637132, 'test:': 20.893639927960518},\n",
       "    {'obj': 12.364429, 'test:': 20.883990094438026},\n",
       "    {'obj': 12.840213, 'test:': 20.874244374928953},\n",
       "    {'obj': 12.207586, 'test:': 20.86442681747205},\n",
       "    {'obj': 11.285285, 'test:': 20.85456576265186},\n",
       "    {'obj': 10.939964, 'test:': 20.84467905589259},\n",
       "    {'obj': 11.103548, 'test:': 20.834774177640686},\n",
       "    {'obj': 11.027056, 'test:': 20.82484817037918}],\n",
       "   'mse': 20.82484817037918,\n",
       "   'baseline': 20.92197617152311,\n",
       "   'dataset_len': 1377},\n",
       "  {'data_path': 'data/Electronics_5.json.gz',\n",
       "   'batches_folder': 'data/Electronics_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Electronics_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 14.470867, 'test:': 21.764731607316396},\n",
       "    {'obj': 11.611982, 'test:': 21.75472082877437},\n",
       "    {'obj': 10.818131, 'test:': 21.74460489486563},\n",
       "    {'obj': 11.253007, 'test:': 21.734394953757064},\n",
       "    {'obj': 11.507178, 'test:': 21.724099135565613},\n",
       "    {'obj': 11.138083, 'test:': 21.71371818270315},\n",
       "    {'obj': 10.669405, 'test:': 21.70326774078297},\n",
       "    {'obj': 10.449419, 'test:': 21.692760266831666},\n",
       "    {'obj': 10.543349, 'test:': 21.682195735265083},\n",
       "    {'obj': 10.491722, 'test:': 21.671600240262663}],\n",
       "   'mse': 21.671600240262663,\n",
       "   'baseline': 21.774488263574046,\n",
       "   'dataset_len': 822},\n",
       "  {'data_path': 'data/Grocery_and_Gourmet_Food_5.json.gz',\n",
       "   'batches_folder': 'data/Grocery_and_Gourmet_Food_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Grocery_and_Gourmet_Food_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 11.31837, 'test:': 22.442202723286925},\n",
       "    {'obj': 10.805172, 'test:': 22.428993391042255},\n",
       "    {'obj': 10.564233, 'test:': 22.415589844763385},\n",
       "    {'obj': 10.7029915, 'test:': 22.402105831829378},\n",
       "    {'obj': 10.751796, 'test:': 22.388566417672415},\n",
       "    {'obj': 10.653133, 'test:': 22.374911921906804},\n",
       "    {'obj': 10.587993, 'test:': 22.361163267604155},\n",
       "    {'obj': 10.5171995, 'test:': 22.347334687553058},\n",
       "    {'obj': 10.552167, 'test:': 22.333458874035234},\n",
       "    {'obj': 10.503583, 'test:': 22.319534610858348}],\n",
       "   'mse': 22.319534610858348,\n",
       "   'baseline': 22.454820352719253,\n",
       "   'dataset_len': 139},\n",
       "  {'data_path': 'data/Home_and_Kitchen_5.json.gz',\n",
       "   'batches_folder': 'data/Home_and_Kitchen_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Home_and_Kitchen_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 15.16218, 'test:': 21.30862561831284},\n",
       "    {'obj': 12.131056, 'test:': 21.298676652841788},\n",
       "    {'obj': 11.196205, 'test:': 21.288598626468612},\n",
       "    {'obj': 11.705873, 'test:': 21.278440436081848},\n",
       "    {'obj': 11.954353, 'test:': 21.268214808619717},\n",
       "    {'obj': 11.634298, 'test:': 21.25792611231448},\n",
       "    {'obj': 11.049515, 'test:': 21.247574302667616},\n",
       "    {'obj': 10.795759, 'test:': 21.237162662263344},\n",
       "    {'obj': 10.868799, 'test:': 21.22669171760982},\n",
       "    {'obj': 10.887975, 'test:': 21.21616862350403}],\n",
       "   'mse': 21.21616862350403,\n",
       "   'baseline': 21.31835002981567,\n",
       "   'dataset_len': 842},\n",
       "  {'data_path': 'data/Kindle_Store_5.json.gz',\n",
       "   'batches_folder': 'data/Kindle_Store_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Kindle_Store_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 11.366034, 'test:': 20.255623430991214},\n",
       "    {'obj': 10.554953, 'test:': 20.241817039263218},\n",
       "    {'obj': 10.342076, 'test:': 20.227938454529433},\n",
       "    {'obj': 10.461729, 'test:': 20.214035653706702},\n",
       "    {'obj': 10.50902, 'test:': 20.200092949026207},\n",
       "    {'obj': 10.4147835, 'test:': 20.186118009646535},\n",
       "    {'obj': 10.29702, 'test:': 20.172133975193532},\n",
       "    {'obj': 10.218255, 'test:': 20.1581332935973},\n",
       "    {'obj': 10.258746, 'test:': 20.144129376415172},\n",
       "    {'obj': 10.228392, 'test:': 20.13010989247665}],\n",
       "   'mse': 20.13010989247665,\n",
       "   'baseline': 20.269183174240805,\n",
       "   'dataset_len': 271},\n",
       "  {'data_path': 'data/Movies_and_TV_5.json.gz',\n",
       "   'batches_folder': 'data/Movies_and_TV_5',\n",
       "   'batch_size': 8192,\n",
       "   'args': {'input': 'data/Movies_and_TV_5.json.gz',\n",
       "    'split': 100,\n",
       "    'factors': 5,\n",
       "    'epochs': 10,\n",
       "    'learning_rate': 0.001,\n",
       "    'regularization': 0.0001},\n",
       "   'results': [{'obj': 11.419355, 'test:': 20.060148865291843},\n",
       "    {'obj': 10.272885, 'test:': 20.048520891537002},\n",
       "    {'obj': 9.98253, 'test:': 20.036787597641354},\n",
       "    {'obj': 10.14324, 'test:': 20.02499884725419},\n",
       "    {'obj': 10.222446, 'test:': 20.013152086456508},\n",
       "    {'obj': 10.137994, 'test:': 20.00124256380731},\n",
       "    {'obj': 9.863611, 'test:': 19.989263542630155},\n",
       "    {'obj': 9.758319, 'test:': 19.97723203040775},\n",
       "    {'obj': 9.808645, 'test:': 19.965163720742435},\n",
       "    {'obj': 9.825625, 'test:': 19.95306424762465}],\n",
       "   'mse': 19.95306424762465,\n",
       "   'baseline': 20.071446623960284,\n",
       "   'dataset_len': 416}])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2c8b2dd7d4083bc367be64571948bb3c2c979e4a38ad29a2bfed21eda93f8d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
