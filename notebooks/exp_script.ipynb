{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the meta data\n",
    "\n",
    "data = []\n",
    "with gzip.open('../data/Kindle_Store_5.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kindle Store set possible analysis\n",
    "- Number of users\n",
    "- Number of items\n",
    "- Average rating\n",
    "- Anything common in high/low rating entries\n",
    "- relationship between length of review and rating\n",
    "- Can any inference be reached by knowing whether an entry is unverified/verified\n",
    "- Temporal analysis\n",
    "- Analyse summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other dataset possible analysis and task\n",
    "- Check other dataset for analysing anything else\n",
    "- Try to use image in other dataset\n",
    "- Some datasets contained votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible features for rating prediction (for Kindle Store)\n",
    "- User-Item interactions (Latent Factor model)\n",
    "- Rating based on review and summary content\n",
    "- Can style be used as feature somehow?\n",
    "- Review time as feature or contributor in rating prediction.\n",
    "- particular temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 5.0,\n",
       " 'verified': False,\n",
       " 'reviewTime': '06 16, 2015',\n",
       " 'reviewerID': 'A1QVFF16PGHKLR',\n",
       " 'asin': 'B00JCJBYDC',\n",
       " 'style': {'Format:': ' Kindle Edition'},\n",
       " 'reviewerName': 'Scottica R',\n",
       " 'reviewText': \"I really enjoyed this story. I loved the fact the characters are going through normal day to day issues. I loved the plot. Jenn has to finally let go of the past in order to find the happiness.  I'm hooked and want more\",\n",
       " 'summary': 'taking chances',\n",
       " 'unixReviewTime': 1434412800}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:len(data)//2]\n",
    "valid_data = data[len(data)//2:(3*(len(data)//4))]\n",
    "test_data = data[(3*(len(data)//4)):]\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_latent_form(entry):\n",
    "    return [entry['reviewerID'], entry['asin'], entry['overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_latent = []\n",
    "for d in train_data:\n",
    "    train_data_latent.append(data_latent_form(d))\n",
    "\n",
    "valid_data_latent = []\n",
    "for d in valid_data:\n",
    "    valid_data_latent.append(data_latent_form(d))\n",
    "\n",
    "test_data_latent = []\n",
    "for d in test_data:\n",
    "    test_data_latent.append(data_latent_form(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings = defaultdict(list)\n",
    "allRatings = []\n",
    "for _,_,r in train_data_latent:\n",
    "  r = int(r)\n",
    "  allRatings.append(r)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "\n",
    "allRatings = []\n",
    "for l in train_data_latent:\n",
    "    allRatings.append(l)\n",
    "\n",
    "beta_u = defaultdict(int)\n",
    "beta_i = defaultdict(int)\n",
    "gamma_u = defaultdict(list)\n",
    "gamma_i = defaultdict(list)\n",
    "alpha = 0\n",
    "for u,b,_ in allRatings:\n",
    "    if not beta_u[u]: beta_u[u] = 0\n",
    "    if not beta_i[b]: beta_i[b] = 0\n",
    "    if not gamma_u[u]: gamma_u[u] = [0.5,0.2]\n",
    "    if not gamma_i[b]: gamma_i[b] = [0.5,0.2]\n",
    "\n",
    "booksPerUser = defaultdict(set)\n",
    "usersPerBook = defaultdict(set)\n",
    "training_count = 0\n",
    "alpha_temp = 0\n",
    "beta_u_temp = 0\n",
    "beta_i_temp = 0\n",
    "reg_param = 10\n",
    " \n",
    "\n",
    "for u,b,r in allRatings:\n",
    "    gamma_prod = 0\n",
    "    for j in range(len(gamma_u[u])):\n",
    "        gamma_prod += (gamma_u[u][j] * gamma_i[b][j])\n",
    "    r_pred = alpha + beta_u[u] + beta_i[b] + gamma_prod\n",
    "    alpha_temp = ((training_count * alpha) + (r - r_pred + alpha))\n",
    "    training_count += 1\n",
    "    alpha_temp /=  training_count\n",
    "    beta_u_temp = (((reg_param + len(booksPerUser[u])) * beta_u[u]) + (r - r_pred + beta_u[u]))\n",
    "    beta_u_temp /= (reg_param + len(booksPerUser[u]) + 1)\n",
    "    beta_i_temp = (((reg_param + len(usersPerBook[b])) * beta_i[b]) + (r - r_pred + beta_i[b]))\n",
    "    beta_i_temp /= (reg_param + len(usersPerBook[b]) + 1)\n",
    "    gamma_u_temp = []\n",
    "    gamma_i_temp = []\n",
    "    for j in range(len(gamma_u[u])):\n",
    "        \n",
    "        temp_u = (((reg_param + (len(booksPerUser[u]) * (gamma_i[b][j] ** 2))) * gamma_u[u][j]) + \n",
    "                (gamma_i[b][j] * (r - r_pred + (gamma_u[u][j] * gamma_i[b][j]))))\n",
    "        temp_i = (((reg_param + (len(usersPerBook[b]) * (gamma_u[u][j] ** 2))) * gamma_i[b][j]) + \n",
    "                (gamma_u[u][j] * (r - r_pred + (gamma_u[u][j] * gamma_i[b][j]))))\n",
    "        temp_u /= (reg_param + ((len(booksPerUser[u]) + 1) * (gamma_i[b][j] ** 2)))\n",
    "        temp_i /= (reg_param + ((len(usersPerBook[b]) + 1) * (gamma_u[u][j] ** 2)))\n",
    "        \n",
    "        gamma_u_temp.append(temp_u)\n",
    "        gamma_i_temp.append(temp_i)\n",
    "    \n",
    "    booksPerUser[u].add(b)\n",
    "    usersPerBook[b].add(u)\n",
    "    alpha = alpha_temp\n",
    "    beta_u[u] = beta_u_temp\n",
    "    beta_i[b] = beta_i_temp\n",
    "    for j in range(len(gamma_u[u])):\n",
    "        gamma_u[u][j] = gamma_u_temp[j]\n",
    "        gamma_i[b][j] = gamma_i_temp[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6860897385145786\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "ypred = []\n",
    "for u,b,r in test_data_latent:\n",
    "    y.append(r)\n",
    "    if u in beta_u and b in beta_i:\n",
    "        gamma_prod = 0\n",
    "        for j in range(len(gamma_u[u])):\n",
    "            gamma_prod += (gamma_u[u][j] * gamma_i[b][j])\n",
    "        ypred.append(alpha + beta_u[u] + beta_i[b] + gamma_prod)\n",
    "    elif u in beta_u and not b in beta_i:\n",
    "        ypred.append(alpha + beta_u[u])\n",
    "    elif not u in beta_u and b in beta_i:\n",
    "        ypred.append(alpha + beta_i[b])\n",
    "    else:\n",
    "        ypred.append(globalAverage)\n",
    "    if ypred[-1] < 0 or ypred[-1] > 5:\n",
    "        if ypred[-1] < 0: ypred[-1] = 0\n",
    "        else: ypred[-1] = 5\n",
    "    ypred[-1] = round(ypred[-1])\n",
    "y = numpy.array(y)\n",
    "ypred = numpy.array(ypred)\n",
    "validMSE = numpy.asarray(sum([x**2 for x in (y - ypred)])) / len(y)\n",
    "print(validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5. 5. 5. 4. 5. 4. 5. 4. 5.]\n",
      "[4 5 4 4 4 4 3 5 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(y[1000:1010])\n",
    "print(ypred[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.395823268024662"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46085279148506136"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square( y[1000:1010] - globalAverage ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
